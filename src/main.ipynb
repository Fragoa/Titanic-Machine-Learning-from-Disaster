{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "accc6b8f-1860-4080-81cf-9ac6bd436869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d970748a-6215-4af8-b36f-0eba319aa041",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join('..', 'dataset', 'train.csv')\n",
    "file_path_response_format = os.path.join('..', 'dataset', 'gender_submission.csv')  \n",
    "file_path_test = os.path.join('..', 'dataset', 'test.csv')\n",
    "\n",
    "train_df = pd.read_csv(file_path)\n",
    "df_response_format = pd.read_csv(file_lath_response_format)\n",
    "df_test = pd.read_csv(file_path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a27fdbb9-1713-4263-8916-3b868666ff78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train Dataset information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Train Dataset information:\")\n",
    "print(train_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "320dcbf7-0ea5-47ed-93c5-568e02f6abad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test Dataset information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          332 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         417 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Test Dataset information:\")\n",
    "print(df_test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02b61e5b-e15d-44ce-bd9c-5660854f2bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Response Formt Dataset information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype\n",
      "---  ------       --------------  -----\n",
      " 0   PassengerId  418 non-null    int64\n",
      " 1   Survived     418 non-null    int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 6.7 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Response Formt Dataset information:\")\n",
    "print(df_response_format.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9efb71bf-ec84-4694-a116-b6b8448dcfe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset descriptive statistics:\n",
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDataset descriptive statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5385fc51-efa3-4542-b474-a109f2e499c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of missing values per column:\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nNumber of missing values per column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5ef88304-7710-420e-b9f3-8abc08c2a83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values per numerical feature before dropping:\n",
      "Pclass      0\n",
      "Age       177\n",
      "SibSp       0\n",
      "Parch       0\n",
      "Fare        0\n",
      "dtype: int64\n",
      "\n",
      "Shape of X_numerical before dropping NaN: (891, 5)\n",
      "Shape of y before dropping NaN: (891,)\n",
      "Shape of X_numerical after dropping NaN: (714, 5)\n",
      "Shape of y after dropping NaN: (714,)\n"
     ]
    }
   ],
   "source": [
    "y = train_df['Survived']\n",
    "\n",
    "numerical_features = train_df.select_dtypes(include=['int64', 'float64']).drop(['Survived', 'PassengerId'], axis=1).columns\n",
    "\n",
    "X_numerical = train_df[numerical_features].copy() \n",
    "\n",
    "print(\"Number of NaN values per numerical feature before dropping:\")\n",
    "print(X_numerical.isnull().sum())\n",
    "\n",
    "nan_rows_index = X_numerical[X_numerical.isnull().any(axis=1)].index\n",
    "\n",
    "X_numerical_cleaned = X_numerical.dropna()\n",
    "\n",
    "y_cleaned = y.drop(nan_rows_index)\n",
    "\n",
    "print(\"\\nShape of X_numerical before dropping NaN:\", X_numerical.shape)\n",
    "print(\"Shape of y before dropping NaN:\", y.shape)\n",
    "print(\"Shape of X_numerical after dropping NaN:\", X_numerical_cleaned.shape)\n",
    "print(\"Shape of y after dropping NaN:\", y_cleaned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1a83db01-c117-43ef-975c-fe2db0c0eba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scaled numerical features (StandardScaler) after dropping NaN:\n",
      "     Pclass       Age     SibSp     Parch      Fare\n",
      "0  0.911232 -0.530377  0.524570 -0.505895 -0.518978\n",
      "1 -1.476364  0.571831  0.524570 -0.505895  0.691897\n",
      "2  0.911232 -0.254825 -0.551703 -0.505895 -0.506214\n",
      "3 -1.476364  0.365167  0.524570 -0.505895  0.348049\n",
      "4  0.911232  0.365167 -0.551703 -0.505895 -0.503850\n",
      "\n",
      "Shape of scaled features (X_scaled): (714, 5)\n",
      "Shape of the cleaned label (y_cleaned): (714,)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaled = scaler.fit_transform(X_numerical_cleaned)\n",
    "\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=numerical_features)\n",
    "\n",
    "print(\"\\nScaled numerical features (StandardScaler) after dropping NaN:\")\n",
    "print(X_scaled_df.head())\n",
    "\n",
    "print(\"\\nShape of scaled features (X_scaled):\", X_scaled.shape)\n",
    "print(\"Shape of the cleaned label (y_cleaned):\", y_cleaned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d2eca3aa-4a08-4707-9d3d-047d6943e9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of XGBoost on the test set: 0.6923\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled_df, y_cleaned, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the XGBoost classifier\n",
    "xgb_classifier = XGBClassifier(random_state=42)\n",
    "xgb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = xgb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy of XGBoost on the test set: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e006add1-42cc-4f1b-bd13-c891722cb0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of XGBoost with feature engineering: 0.7933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/55/ckz71qcd6zz56zdm9qthg9v40000gn/T/ipykernel_76390/3551535491.py:25: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X['Title'].replace(['Lady', 'Countess','Capt', 'Col',\n"
     ]
    }
   ],
   "source": [
    "# جدا کردن ویژگی (X) و برچسب (y)\n",
    "X = train_df.drop('Survived', axis=1)\n",
    "y = train_df['Survived']\n",
    "\n",
    "# 1. مدیریت مقادیر از دست رفته\n",
    "X['Age'] = X['Age'].fillna(X['Age'].mean())\n",
    "X['Embarked'] = X['Embarked'].fillna(X['Embarked'].mode()[0])\n",
    "# استخراج حرف اول Cabin\n",
    "X['Cabin_initial'] = X['Cabin'].str[0].fillna('Unknown')\n",
    "\n",
    "X['Cabin_known'] = X['Cabin'].apply(lambda x: 0 if pd.isna(x) else 1)\n",
    "X.drop('Cabin', axis=1, inplace=True)  # حذف ستون اصلی Cabin بعد از ایجاد ویژگی Cabin_initial و Cabin_known\n",
    "\n",
    "# 2. مهندسی ویژگی\n",
    "X['FamilySize'] = X['SibSp'] + X['Parch'] + 1\n",
    "X['IsAlone'] = X['FamilySize'].apply(lambda x: 1 if x == 1 else 0)\n",
    "\n",
    "def extract_title(name):\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "X['Title'] = X['Name'].apply(extract_title)\n",
    "X['Title'].replace(['Lady', 'Countess','Capt', 'Col',\n",
    "                    'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare', inplace=True)\n",
    "X['Title'].replace('Mlle', 'Miss', inplace=True)\n",
    "X['Title'].replace('Ms', 'Miss', inplace=True)\n",
    "X['Title'].replace('Mme', 'Mrs', inplace=True)\n",
    "X.drop('Name', axis=1, inplace=True)  # حذف ستون اصلی Name بعد از استخراج Title\n",
    "X.drop('Ticket', axis=1, inplace=True)  # حذف ستون Ticket\n",
    "\n",
    "# 3. انتخاب ویژگی‌ها برای پیش‌پردازش\n",
    "numerical_features = ['Age', 'SibSp', 'Parch', 'Fare', 'FamilySize']\n",
    "categorical_features = ['Sex', 'Pclass', 'Embarked', 'Cabin_known', 'IsAlone', 'Title', 'Cabin_initial']\n",
    "\n",
    "# 4. ایجاد Pipeline برای پیش‌پردازش\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# 5. تقسیم داده‌ها به آموزش و آزمایش\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 6. ایجاد و آموزش مدل XGBoost در یک Pipeline\n",
    "xgb_model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                            ('classifier', XGBClassifier(random_state=42))])\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# 7. پیش‌بینی و ارزیابی مدل\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy of XGBoost with feature engineering: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68db400e-c3c2-4c37-a1b1-0b2bd829da93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
